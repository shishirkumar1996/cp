This folder serves as a template for all the algos and data structures which I might forget in the future.

Algorithms and their Uses


Algorithm                                                   Use

1. tarjan algorithm          ----->    for finding strongly connected component
2. maximum bipartite matching ---->    for finding maximum matching in bipartite graph
3. Edmond Karp(ford fulkerson) algorithm ------>    maximum flow from source to sink in a graph . Edmon karp is a fully applied algorithm of ford fulkerson method
4. hopcroft-karp algorithm    ---->    for finding maximum matching in bipartite graph. It can also be done with ford fulkerson method by just connecting source with all the vertices in first set and connecting sink with all the vertices in second set

5. coin change problem        ---->     dynamic programming problem to check number of ways to return certain amount(change) given infinite number of coins of some types
6. lowest common ancestor(binary lifting method) ---->     in trees, we need to find the lowest common ancestor of two given nodes.
7. Extended euclidean algorithm ------> Finds integer coefficient  x and y such that ax+by = gcd(a,b) ( a and b are given) . The extended Euclidean algorithm is particularly useful when a and b are coprime (or gcd is 1). Since x is the modular multiplicative inverse of “a modulo b”, and y is the modular multiplicative inverse of “b modulo a”. As ax modulo b = 1, therefore a and x are modular multiplicative inverse. ( need to learn it)
8. modular multiplicative inverse ------> used in chinese remainder theorem
9. chinese remainder theorem -----> two arrays are given num[1..n],rem[1..n] and every pair num[i] and rem[i] is coprime, we need to find minimum positive number such that x%num[i] = rem[i] for every pair.
10. modular exponentiation -------> for faster calculation of x^y
11. breadth first search -------> traversal technique
12. depth first search ------> traversal technique(both iterative and recursive)
13. dijkstra algorithm -------> greedy algorithm to find minimum distance from one vertex to all other vertices. Time complexity is O(VlogV)
14. prim algorithm --------> for finding minimum spanning tree of a graph( greedy algorithm)
15. kruskal algorithm-------> for finding minimum spanning tree of a graph
16. heavy-light decomposition algorithm ----> to divide the tree into various chains in order to minimize the query time. As there are atmost log N chains and solution for each chain can be answered in O(log n) time,therefore total time complexity becomes O((logn)^2). Each continues on the vertex which have the greatest number of elements in its subtree
17. merge sort        -------> sorting method with O(nlogn) complexity and works on divide and conquer approach
18. quick sort ----->it also works on divide and conquer approach. A pivot is being selected and the array is divided on the basis of this pivot and then sorted. complexity is O(nlogn)
19. radix sort ------> complexity is O((base b)log(k)*(n+b)) where b is base for representing numbers, n is the number of elements and k is the maximum possible value.Can work in linear time.
20. binary search ----> works on sorted list, to search for a particular element. divide and conquer approach. O(logn) time.
21. z-algorithm ------> find all occurences of a pattern in a text in linear time. If length of text is m and length of pattern is m, then total time taken is O(m+n) with linear space complexity.Same time and space complexity as KMP algo but simpler to understand.works on z-array in which length of longest starting from str[i] is also a prefix of str[0..n-1].
22. kmp algorithm -------> find all occurences of a pattern in a text in linear space complexity. lps array is being created where lps[i] = the longest proper prefix of pat[0..i] which is also a suffix of pat[0..i]. Also prefix function used to calculate lps array can have other applications.
23. fractional knapsack problem -----> greedy approach works for this problem as we can take fraction of an item.
24. 0-1 knapsack problem ------> dynamic programming approach works for this problem as you can either take full item or not at all.
25. rod cutting problem ----> dynamic programming approach.divide the rod into such parts so that the value of the parts become maximum
26. bellman-ford algorithm ----> dynamic programming approach. Finds shortest paths from sources to all vertices in the given graph.The graph may contain negative weight edges.Time complexity is O(VE) where V is number of vertices, E is number of edges. In both bellman ford and prim algorithm, graph is represented as array of edges.
27. floyd warshall algorithm ------> dynamic programming approach. calculates shortest path from each vertex to every other vertex
28. longest increasing subsequence ------> dynamic programming approach has time complexity of O(n^2). But here a method of O(nlogn) is being described.
In dynamic programming approach, we just check all the smaller indices for a given index.
29. longest common subsequence -----> dynamic programming approach. Time complexity is O(mn) where m and n are sizes of two strings.
30. rabin-karp algorithm -------> finds a pattern in a string just like z-algorithm and kmp algorithm. time complexity is O(m+n). Works by calculating hash values of the string.
31. sudoku solving ------> use of backtrack to solve 3*3 sudoku
32. n-queen problem -------> backtracking problem. number of ways to keep n queens on n*n chessboard so that none of them attack any other queen. here just one orientation is being shown. Complexity is exponential. Therefore pruning is also applied to increase efficiency.
33. matrix exponentiation algorithm ------> here, matrix exponentiation is done to calculate f(n) = a*f(n-1)+b*f(n-2)+c*f(n-3) in O(logn) time. similarly fibonacii sequence and other sequence numbers can also be calculated in o(logn) time. the matrices changes as the sequences changes.
34. closest pair of point ------> given n points in the plane,find closes pair of point among the given points. algorithm has divide and conquer approach. The time complexity is O(n(logn)^2).
35. orientation of three points -----> It can be either counterclockwise, clockwise or colinear. This property can be used to find intersection of line segments.
36 topological sorting --------->  Topological sorting for Directed Acyclic Graph (DAG) is a linear ordering of vertices such that for every directed edge u to v, vertex u comes before v in the ordering. Topological Sorting for a graph is not possible if the graph is not a DAG. Useful in solving dynamic programming related problem. Time complexity is same as dfs of O(V+E).
37.articulation point -----------> A vertex in an undirected connected graph is an articulation point (or cut vertex) iff removing it (and edges through it) disconnects the graph.For a disconnected undirected graph, an articulation point is a vertex removing which increases number of connected components.Here O(V+E) algorithm is given to find articulation points.
38. graph coloring problem -----> The problem is, given m colors, find a way of coloring the vertices of a graph such that no two adjacent vertices are colored using same color. The other graph coloring problems like Edge Coloring (No vertex is incident to two edges of same color) and Face Coloring (Geographical Map Coloring) can be transformed into vertex coloring.Chromatic Number: The smallest number of colors needed to color a graph G is called its chromatic number. This problem is NP complete as no efficient algorithm is available. There is  a basic greedy algorithm which doesn't guarantee minimum colors but an upper bound on the number of colors. this never uses more than d+1 colors where d is the maximum degree of vertex in the given graph
39. travelling salesman problem ------> Given a set of cities and distance between every pair of cities, the problem is to find the shortest possible route that visits every city exactly once and returns to the starting point. This is an NP hard problem. Here dynamic programming solution is discussed which have O(n^2*2^n) complexity. There is another MST based implementation also which is faster but gives approximate value. The algorithm is 2-approximate.
40. Hamiltonian cycle --------> Hamiltonian Path in an undirected graph is a path that visits each vertex exactly once. A Hamiltonian cycle (or Hamiltonian circuit) is a Hamiltonian Path such that there is an edge (in graph) from the last vertex to the first vertex of the Hamiltonian Path. Determine whether a given graph contains Hamiltonian Cycle or not. Here backtracking approach is being discussed.
41. Centroid decomposition ------> given a tree with  n nodes, a centroid is a node whose removal splits the given tree into a forest of trees, where each of the resulting tree contains no more than N/2 nodes.Centroid tree has depth O(lg n) and can be constructed in O(n lgn) as centroid can be find in O(n).
42. aho-corasick algorithm -----> Given an input text and an array of k words, arr[], find all occurrences of all words in the input text. Let n be the length of text and m be the total number characters in all words, i.e. m = length(arr[0]) + length(arr[1]) + … + length(arr[k-1]). Here k is total numbers of input words. time complexity is O(n+m+z) where z is the total number of occurences of words in text. This algorithm uses trie.
43. set cover problem ------> Given a universe U of n elements, a collection of subsets of U say S = {S1, S2…,Sm} where every subset Si has an associated cost. Find a minimum cost subcollection of S that covers all elements of U. It is an NP hard problem and 2-approximate greedy algorithm is given here.
44. Sieve of Eratosthenes -------> This method is used to calculate all the prime numbers. Here also altered a bit to find all the divisors of a number in O(nlog(logn)).
45. Euler totient sieve or Euler phi sieve -------> totient of phi function is the number phi(a) is the number of positive integers less than a that is relatively prime to a. Complexity is O(n log(logn)) because it does the inner loop only if the number is prime.
46. Linear sieve    ------------>  Calculates the prime numbers numbers in segment[2...n] in O(logn) time. The goal is to calculate minimum prime factor for every number.
47. mobius function -------> It is a multiplicative function which is used in combinatorics. It has three possible values 1, 0, and -1. u(n) = 1 for n - 1, u(n) = 0 if a*a|n(a*a divides n) for some a > 1(i.e. n has a squared prime factor), u(n) = (-1)^k if n is the product of k distinct primes. It is one of the multiplicative functions according to which For every co-prime pair of integers p and q, f(pq) = f(p)f(q).
48. catalan numbers --------> a special series which have many interesting applications. Here a dynamic programming approach of O(n^2) is given. An approach of O(n) complexity based on binomial coefficient is also present which is not discussed here.
49. max flow push-relabel algorithm -------->   It is used to find maximum flow from source to sink. The discussed approach works in O(V*V*E) time.
50. 2-satsfiability(2-sat) problem ----------> It is the problem of determining whether boolean formula is satisfiable(true in some condition) or unsatisfiable(false in every condition). Boolean satisfiability is an NP complete problem but 2-sat is a special case of boolean satisfiability. Here SCC condition is checked with Kosaraju algorithm in O(E+V) time.
The given expressions are of the form (a1 or a2) and ( b1 or b2) and (c1 or c2) and (d1 or d2) etc.
51. prufer code -------> It is a sequence which uniquely identifies a tree. we can convert prufer code to tree and vice versa.
52. Distance between point and line segment -------> It can be useful in bigger problems.
53. area of a polygon -------> can be useful in bigger problem
54. mo's algorithm(query square root decomposition) -------> This is an offline algorithm which is used to give query based answers by sorting the queries.Let n be the size of the array and m be the size of the query. Preprocessing takes O(mlogm) time .Answering all queries take O((m+n)*sqrt(n)).
55. kadane algorithm -------> It is used to find maximum contigous subsequence sum in O(n) time.
56. Fast fourier transformation for polynomial multiplication ------> naive method takes O(n^2) time but through fft it takes O(nlogn) time. Here conversion from poynomial form to point value form is shown correctly.Some correction  is needed in inverse fft
57. manacher algorithm ---------> It is used to find longest substring which is palindrome in linear time.
58. Kasai algorithm(also creates suffix array) ----> It is used for construction of LCP(lowest common prefix) array from suffix array.LCP Array is an array of size n (like Suffix Array). A value lcp[i] indicates length of the longest common prefix of the suffixes inexed by suffix[i] and suffix[i+1]. suffix[n-1] is not defined as there is no suffix after it. The algo takes O(m*logn) time where m is the length of the pattern to be searched and n is the length of the text. Suffix array construction takes O(nlogn).
59. Ukkonen algorithm -------> It is used to create implicit suffix tree. Suffix tree is a copmressed suffix trie, so all vertices which are not corresponding to suffixes and which have only one descendant are omitted.
60. Dinic algorithm -----------> Time complexity is O(EV^2). It is the algorithm to find maximum flow from source to sink.
61. sparse table ---------> Sparse table concept is used for fast queries on a set of static data (elements do not change). It does preprocessing so that the queries can answered efficiently. Here it is applied on range minimum query.
62. number of transposition in a permutation ------> Cycle notation A permutation can be represented as a composition of permutation cycles. A permutation cycle is a set of elements in a permutation which trade places with one another.The number of transpositions in a permutation is important as it gives the minimum number of 2 element swaps required to get this particular arrangement from the identity arrangement: 1, 2, 3, … n. The parity of the number of such 2 cycles represents whether the permutation is even or odd.number of transpositions from a cycle = length of the cycle – 1.
63. rotation of one point around another point -----> Two points are given and one point is to be rotated around another point about some given angle. Positive angle means anti-clockwise rotation. point is represented as complex as rotation becomes easier in this case.
64. square check ------> given four points, check whether they form square or not.
65. diameter of a tree -----------> diameter is the maximum distance between any two nodes in a tree.
66. cycle vertices in undirected graph and directed graph-------> Sometimes necessity arise not to check whether there is a cycle or not but to check which vertices are in a cycle.Here it is assumed that the graph is a tree and not a forest. directed graph method is through scc method.
67. kosaraju algorithm --------> it is used to check scc in a graph
68. geometry primitives ---------> small geometry algos like dot product cross product which have bigger applications while calculting area of polygon or other complex operations.
69. meet in the middle---------> It is a search technique which is used when the input is small but not as small that brute force can be used Like divide and conquer it splits the problem into two, solves them individually and then merge them. But we can't apply meet in the middle like divide and conquer because we don't have the same structure as the original problem.Here maximum sum subset problem is discussed where we have to find a subset having maximum sum less than or equal to S.
70. fermat's little theorem ---------> It states that if p is a prime number, then for any integer a, the number a^p is an integer multiple of p.
  More formally a^p ≡ a(mod p). for special case if a is not divisible by p,  then a^(p-1)  ≡ 1(mod p). Therefore if we know p is prime, then we can also use this theorem to find the inverse a^(p-1) ≡ 1(mod p) which is equivalent to a^(-1)  ≡ a^(p-2)(mod p)
71. modular division ----------> Given three positive numbers a, b and m. Compute a/b under modulo m. The task is basically to find a number c such that (b * c) % m = a % m. modular division is only defined when modular inverse of the divisor exist. inverse a number ‘a’ exists under modulo ‘m’ if ‘a’ and ‘m’ are co-prime, i.e., GCD of them is 1. Therefore if combined with fermat little theorem it can give easy solution for the inverse. Then (a/b)mod p will be equivalent to (a*pow(b,p-2))mod p.
72. tree traversal ----------> The in and out time of the vertices are stored and all the vertices belong to the subtree of a specific vertex which have in time between the in and out time of the given verte.


Data structure

1. disjoint set union (DSU) ------> can be used for 1) cycle checks  (check kruskal for implementation).
2. segment tree -------> Is used to update and query a range in O(logn) time. time complexity of tree construction is O(n). lazy propogation is also added which is used to a range update which updates a particular node only when necessary.
3. persistent segment tree ------------> It is used to store to retain the changes which are being done in the segment tree. With each version change only log(n) nodes will be atmost changed therefore O(logn) time and space will change.(main function yet to be written)
4. fenwick tree(binary indexed tree) -------------->A Fenwick Tree is a data structure that represents an array of n numbers. It supports adjusting the i-th element in O(log n) time, and computing the sum of numbers in the range i..j in O(log n)
time. It only needs O(n) space.
5. trie ------------> Trie is an efficient information reTrieval data structure. Using Trie, search complexities can be brought to optimal limit (key length). If we store keys in binary search tree, a well balanced BST will need time proportional to M * log N, where M is maximum string length and N is number of keys in tree. Using Trie, we can search the key in O(M) time.Every node of Trie consists of multiple branches. Each branch represents a possible character of keys. We need to mark the last node of every key as end of word node. A Trie node field isEndOfWord is used to distinguish the node as end of word node.
6. sparse table -------> It is used for fast queries on a set of static data. It does preprocessing so that the queries can be answered efficiently.Here sparse table on rmq(range minimum query) is discussed.
7. hashing ------------> It gives a unique integral value for different strings. Only two equal strings have two equal integral values.the modulus must be a large prime to avoid collisions.
